{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Charley Padron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accuracy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "\n",
    "\n",
    "4. Upload the .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. On Canvas, submit the Google Drive/Dropbox/Github link to the HTML file.\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    results = numpy.zeros((len(y), num_class))\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 2, 2, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052,522\n",
      "Trainable params: 2,049,578\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dropout(0.12))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#learning_rate = 1E-5 # to be tuned!\n",
    "#learning_rate = 1E-4 # to be tuned!\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "#learning_rate = 1E-2 # to be tuned!\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "#rotation_range=40,\n",
    "#rotation_range=20,\n",
    "rotation_range=10,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen.fit(x_tr)\n",
    "\n",
    "b=32\n",
    "\n",
    "train_generator = train_datagen.flow(x_tr, y_tr, batch_size=b)\n",
    "val_generator = val_datagen.flow(x_val, y_val, batch_size=b)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 142s 111ms/step - loss: 1.8654 - acc: 0.3007 - val_loss: 1.7841 - val_acc: 0.3648\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 138s 110ms/step - loss: 1.5067 - acc: 0.4436 - val_loss: 1.6010 - val_acc: 0.4776\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 133s 107ms/step - loss: 1.3419 - acc: 0.5137 - val_loss: 1.5867 - val_acc: 0.4920\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 131s 105ms/step - loss: 1.2200 - acc: 0.5684 - val_loss: 1.1163 - val_acc: 0.6102\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 141s 113ms/step - loss: 1.1347 - acc: 0.6006 - val_loss: 1.6555 - val_acc: 0.5266\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 136s 109ms/step - loss: 1.0604 - acc: 0.6331 - val_loss: 1.1079 - val_acc: 0.6352\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 138s 110ms/step - loss: 1.0108 - acc: 0.6520 - val_loss: 1.1495 - val_acc: 0.6188\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 138s 110ms/step - loss: 0.9560 - acc: 0.6703 - val_loss: 0.7924 - val_acc: 0.7293\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 129s 103ms/step - loss: 0.9137 - acc: 0.6879 - val_loss: 0.8162 - val_acc: 0.7218\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 129s 103ms/step - loss: 0.8787 - acc: 0.7000 - val_loss: 0.9428 - val_acc: 0.7158\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 130s 104ms/step - loss: 0.8507 - acc: 0.7141 - val_loss: 1.0800 - val_acc: 0.6673\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 139s 111ms/step - loss: 0.8270 - acc: 0.7235 - val_loss: 1.2174 - val_acc: 0.6672\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 132s 106ms/step - loss: 0.8049 - acc: 0.7323 - val_loss: 0.7063 - val_acc: 0.7758\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 138s 110ms/step - loss: 0.7884 - acc: 0.7367 - val_loss: 0.6896 - val_acc: 0.7755\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 140s 112ms/step - loss: 0.7706 - acc: 0.7441 - val_loss: 0.9539 - val_acc: 0.6962\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 138s 110ms/step - loss: 0.7493 - acc: 0.7501 - val_loss: 0.7106 - val_acc: 0.7637\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 142s 113ms/step - loss: 0.7297 - acc: 0.7582 - val_loss: 0.8304 - val_acc: 0.7341\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 141s 112ms/step - loss: 0.7173 - acc: 0.7628 - val_loss: 0.6072 - val_acc: 0.7953\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 142s 114ms/step - loss: 0.7045 - acc: 0.7687 - val_loss: 0.6565 - val_acc: 0.7990\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 142s 114ms/step - loss: 0.7029 - acc: 0.7684 - val_loss: 0.8207 - val_acc: 0.7341\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))\n",
    "history = model.fit(train_generator, epochs=20, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#model.save('model.h5')\n",
    "model.save_weights('model')\n",
    "#model.load_weights('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 1E-5 # to be tuned!\n",
    "#learning_rate = 1E-4 # to be tuned!\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "#learning_rate = 1E-2 # to be tuned!\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "rotation_range=10,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "b=32\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train_vec, batch_size=b)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = test_datagen.flow(x_test, y_test_vec)\n",
    "\n",
    "#model = load_model('model.h5')\n",
    "model.load_weights('model')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 161s 102ms/step - loss: 0.7012 - acc: 0.7672\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 153s 98ms/step - loss: 0.6811 - acc: 0.7771\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 159s 102ms/step - loss: 0.6734 - acc: 0.7802\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 155s 99ms/step - loss: 0.6656 - acc: 0.7816\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 156s 100ms/step - loss: 0.6509 - acc: 0.7867\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 183s 117ms/step - loss: 0.6381 - acc: 0.7911\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 142s 91ms/step - loss: 0.6353 - acc: 0.7915\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.6213 - acc: 0.7971\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.6145 - acc: 0.7983\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 140s 89ms/step - loss: 0.6160 - acc: 0.8008\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.5986 - acc: 0.8053\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 146s 93ms/step - loss: 0.5938 - acc: 0.8058\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 146s 93ms/step - loss: 0.5908 - acc: 0.8080\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 142s 91ms/step - loss: 0.5816 - acc: 0.8099\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 146s 93ms/step - loss: 0.5784 - acc: 0.8127\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 147s 94ms/step - loss: 0.5756 - acc: 0.8128\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 146s 93ms/step - loss: 0.5685 - acc: 0.8147\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.5720 - acc: 0.8156\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.5628 - acc: 0.8158\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.5548 - acc: 0.8190\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(x_train, y_train_vec, batch_size=32, epochs=20)\n",
    "history = model.fit(train_generator, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.5556 - acc: 0.8190\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.5488 - acc: 0.8208\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 135s 86ms/step - loss: 0.5380 - acc: 0.8248\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.5376 - acc: 0.8255\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.5368 - acc: 0.8267\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.5389 - acc: 0.8234\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.5287 - acc: 0.8273\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 0.5393 - acc: 0.8264\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.5329 - acc: 0.8292\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.5227 - acc: 0.8306\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('model')\n",
    "model.load_weights('model')\n",
    "history = model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.5125 - acc: 0.8353\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 146s 93ms/step - loss: 0.5094 - acc: 0.8365\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 140s 90ms/step - loss: 0.5083 - acc: 0.8363\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 138s 89ms/step - loss: 0.5070 - acc: 0.8379\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.5084 - acc: 0.8380\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('model')\n",
    "model.load_weights('model')\n",
    "history = model.fit(train_generator, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e6a96d4550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('model')\n",
    "model.load_weights('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 19ms/step - loss: 0.5514 - acc: 0.8317\n",
      "loss = 0.5514371395111084\n",
      "accuracy = 0.8317000269889832\n"
     ]
    }
   ],
   "source": [
    "#loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "loss_and_acc = model.evaluate(test_generator)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
